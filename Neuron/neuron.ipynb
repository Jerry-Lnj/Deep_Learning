{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1512e0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_batch_1', 'readme.html', 'batches.meta', 'data_batch_2', 'data_batch_5', 'test_batch', 'data_batch_4', 'data_batch_3']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "CIFAR_DIR = \"./cifar-10-batches-py\"\n",
    "print(os.listdir(CIFAR_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd12ff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"read data from data file\"\"\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = pickle.load(f, encoding='latin1')\n",
    "        return data['data'], data['labels']\n",
    "    \n",
    "class CifarData:\n",
    "    def __init__(self, filenames, need_shuffle):\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        for filename in filenames:\n",
    "            data, labels = load_data(filename)\n",
    "            for item, label in zip(data, labels):\n",
    "                if label in [0,1]:\n",
    "                    all_data.append(item)\n",
    "                    all_labels.append(label)\n",
    "        self._data = np.vstack(all_data)\n",
    "        self._data = self._data / 127.5 -1\n",
    "        self._labels = np.hstack(all_labels)\n",
    "        #print(self._data.shape)\n",
    "        #print(self._labels.shape)\n",
    "        self._num_examples = self._data.shape[0]\n",
    "        self._need_shuffle = need_shuffle\n",
    "        self._indicator = 0\n",
    "        if self._need_shuffle:\n",
    "            self._shuffle_data()\n",
    "    \n",
    "    def _shuffle_data(self):\n",
    "        p = np.random.permutation(self._num_examples)\n",
    "        self._data = self._data[p]\n",
    "        self._labels = self._labels[p]\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self._num_examples:\n",
    "            if self._need_shuffle:\n",
    "                self._shuffle_data()\n",
    "                self._indicator = 0\n",
    "                end_indicator = batch_size\n",
    "            else:\n",
    "                raise Exception(\"have no more examples\")\n",
    "                    \n",
    "        if end_indicator > self._num_examples:\n",
    "            raise Exception(\"batch size is larger than all examples\")\n",
    "        batch_data = self._data[self._indicator: end_indicator]\n",
    "        batch_labels = self._labels[self._indicator: end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data, batch_labels\n",
    "    \n",
    "train_filenames = [os.path.join(CIFAR_DIR, 'data_batch_%d' %i) for i in range(1,6)]\n",
    "test_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\n",
    "\n",
    "train_data = CifarData(train_filenames, True)\n",
    "test_data = CifarData(test_filenames, False)\n",
    "\n",
    "#batch_data, batch_labels = train_data.next_batch(10)\n",
    "#print(batch_data)\n",
    "#print(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e32aac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()    \n",
    "# This function can only be called before any Graphs, Ops, or Tensors have been created. \n",
    "# It can be used at the beginning of the program for complex migration projects from TensorFlow 1.x to 2.x.\n",
    "\n",
    "x = tf.compat.v1.placeholder(tf.float32, [None,3072])    \n",
    "y = tf.compat.v1.placeholder(tf.int64, [None])    \n",
    "\n",
    "w = tf.compat.v1.get_variable('w', [x.get_shape()[-1], 1], initializer=tf.random_normal_initializer(0,1))\n",
    "b = tf.compat.v1.get_variable('b', [1], initializer= tf.constant_initializer(0.0))\n",
    "y_ = tf.matmul(x, w) + b\n",
    "\n",
    "p_y_1 = tf.nn.sigmoid(y_)\n",
    "y_reshaped = tf.reshape(y,(-1,1))    \n",
    "y_reshaped_float = tf.cast(y_reshaped, tf.float32)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y_reshaped_float - p_y_1))\n",
    "predict = p_y_1 > 0.5\n",
    "correct_prediction = tf.equal(tf.cast(predict, tf.int64), y_reshaped)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    train_op = tf.compat.v1.train.AdamOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4888b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step: 499, loss: 0.33097, acc:0.60000\n",
      "[Train] Step: 999, loss: 0.30394, acc:0.70000\n",
      "[Train] Step: 1499, loss: 0.10084, acc:0.90000\n",
      "[Train] Step: 1999, loss: 0.19999, acc:0.80000\n",
      "[Train] Step: 2499, loss: 0.24540, acc:0.75000\n",
      "[Train] Step: 2999, loss: 0.38930, acc:0.60000\n",
      "[Train] Step: 3499, loss: 0.15199, acc:0.85000\n",
      "[Train] Step: 3999, loss: 0.17044, acc:0.80000\n",
      "[Train] Step: 4499, loss: 0.14214, acc:0.85000\n",
      "[Train] Step: 4999, loss: 0.39017, acc:0.60000\n",
      "[Test] Step: 5000, acc: 0.81000\n",
      "[Train] Step: 5499, loss: 0.21992, acc:0.75000\n",
      "[Train] Step: 5999, loss: 0.37961, acc:0.60000\n",
      "[Train] Step: 6499, loss: 0.25178, acc:0.75000\n",
      "[Train] Step: 6999, loss: 0.13443, acc:0.85000\n",
      "[Train] Step: 7499, loss: 0.10003, acc:0.90000\n",
      "[Train] Step: 7999, loss: 0.16963, acc:0.80000\n",
      "[Train] Step: 8499, loss: 0.44999, acc:0.55000\n",
      "[Train] Step: 8999, loss: 0.10013, acc:0.90000\n",
      "[Train] Step: 9499, loss: 0.17337, acc:0.80000\n",
      "[Train] Step: 9999, loss: 0.34952, acc:0.65000\n",
      "[Test] Step: 10000, acc: 0.81200\n",
      "[Train] Step: 10499, loss: 0.08600, acc:0.90000\n",
      "[Train] Step: 10999, loss: 0.14126, acc:0.85000\n",
      "[Train] Step: 11499, loss: 0.05127, acc:0.95000\n",
      "[Train] Step: 11999, loss: 0.15430, acc:0.85000\n",
      "[Train] Step: 12499, loss: 0.20370, acc:0.80000\n",
      "[Train] Step: 12999, loss: 0.05247, acc:0.95000\n",
      "[Train] Step: 13499, loss: 0.10004, acc:0.90000\n",
      "[Train] Step: 13999, loss: 0.04832, acc:0.95000\n",
      "[Train] Step: 14499, loss: 0.18393, acc:0.80000\n",
      "[Train] Step: 14999, loss: 0.25932, acc:0.70000\n",
      "[Test] Step: 15000, acc: 0.82000\n",
      "[Train] Step: 15499, loss: 0.16053, acc:0.85000\n",
      "[Train] Step: 15999, loss: 0.09993, acc:0.90000\n",
      "[Train] Step: 16499, loss: 0.23375, acc:0.75000\n",
      "[Train] Step: 16999, loss: 0.14943, acc:0.85000\n",
      "[Train] Step: 17499, loss: 0.27138, acc:0.70000\n",
      "[Train] Step: 17999, loss: 0.19654, acc:0.80000\n",
      "[Train] Step: 18499, loss: 0.15868, acc:0.85000\n",
      "[Train] Step: 18999, loss: 0.20435, acc:0.80000\n",
      "[Train] Step: 19499, loss: 0.18169, acc:0.80000\n",
      "[Train] Step: 19999, loss: 0.10578, acc:0.90000\n",
      "[Test] Step: 20000, acc: 0.81850\n",
      "[Train] Step: 20499, loss: 0.15003, acc:0.85000\n",
      "[Train] Step: 20999, loss: 0.00024, acc:1.00000\n",
      "[Train] Step: 21499, loss: 0.10185, acc:0.90000\n",
      "[Train] Step: 21999, loss: 0.15000, acc:0.85000\n",
      "[Train] Step: 22499, loss: 0.14127, acc:0.85000\n",
      "[Train] Step: 22999, loss: 0.11330, acc:0.85000\n",
      "[Train] Step: 23499, loss: 0.10004, acc:0.90000\n",
      "[Train] Step: 23999, loss: 0.05000, acc:0.95000\n",
      "[Train] Step: 24499, loss: 0.04295, acc:0.95000\n",
      "[Train] Step: 24999, loss: 0.14981, acc:0.85000\n",
      "[Test] Step: 25000, acc: 0.82100\n",
      "[Train] Step: 25499, loss: 0.10129, acc:0.90000\n",
      "[Train] Step: 25999, loss: 0.25984, acc:0.75000\n",
      "[Train] Step: 26499, loss: 0.14835, acc:0.85000\n",
      "[Train] Step: 26999, loss: 0.24530, acc:0.75000\n",
      "[Train] Step: 27499, loss: 0.30000, acc:0.70000\n",
      "[Train] Step: 27999, loss: 0.24881, acc:0.75000\n",
      "[Train] Step: 28499, loss: 0.15014, acc:0.85000\n",
      "[Train] Step: 28999, loss: 0.15000, acc:0.85000\n",
      "[Train] Step: 29499, loss: 0.15095, acc:0.85000\n",
      "[Train] Step: 29999, loss: 0.09128, acc:0.90000\n",
      "[Test] Step: 30000, acc: 0.82200\n",
      "[Train] Step: 30499, loss: 0.15715, acc:0.85000\n",
      "[Train] Step: 30999, loss: 0.24997, acc:0.75000\n",
      "[Train] Step: 31499, loss: 0.10017, acc:0.90000\n",
      "[Train] Step: 31999, loss: 0.14020, acc:0.85000\n",
      "[Train] Step: 32499, loss: 0.20000, acc:0.80000\n",
      "[Train] Step: 32999, loss: 0.15033, acc:0.85000\n",
      "[Train] Step: 33499, loss: 0.15048, acc:0.85000\n",
      "[Train] Step: 33999, loss: 0.25001, acc:0.75000\n",
      "[Train] Step: 34499, loss: 0.15076, acc:0.85000\n",
      "[Train] Step: 34999, loss: 0.10012, acc:0.90000\n",
      "[Test] Step: 35000, acc: 0.82150\n",
      "[Train] Step: 35499, loss: 0.10057, acc:0.90000\n",
      "[Train] Step: 35999, loss: 0.11750, acc:0.85000\n",
      "[Train] Step: 36499, loss: 0.35445, acc:0.65000\n",
      "[Train] Step: 36999, loss: 0.15008, acc:0.85000\n",
      "[Train] Step: 37499, loss: 0.07692, acc:0.90000\n",
      "[Train] Step: 37999, loss: 0.05000, acc:0.95000\n",
      "[Train] Step: 38499, loss: 0.25000, acc:0.75000\n",
      "[Train] Step: 38999, loss: 0.15091, acc:0.85000\n",
      "[Train] Step: 39499, loss: 0.10124, acc:0.90000\n",
      "[Train] Step: 39999, loss: 0.14994, acc:0.85000\n",
      "[Test] Step: 40000, acc: 0.82550\n",
      "[Train] Step: 40499, loss: 0.05835, acc:0.95000\n",
      "[Train] Step: 40999, loss: 0.22142, acc:0.75000\n",
      "[Train] Step: 41499, loss: 0.20000, acc:0.80000\n",
      "[Train] Step: 41999, loss: 0.05035, acc:0.95000\n",
      "[Train] Step: 42499, loss: 0.10007, acc:0.90000\n",
      "[Train] Step: 42999, loss: 0.10072, acc:0.90000\n",
      "[Train] Step: 43499, loss: 0.10873, acc:0.90000\n",
      "[Train] Step: 43999, loss: 0.15009, acc:0.85000\n",
      "[Train] Step: 44499, loss: 0.16028, acc:0.85000\n",
      "[Train] Step: 44999, loss: 0.11839, acc:0.85000\n",
      "[Test] Step: 45000, acc: 0.81950\n",
      "[Train] Step: 45499, loss: 0.15859, acc:0.85000\n",
      "[Train] Step: 45999, loss: 0.29826, acc:0.70000\n",
      "[Train] Step: 46499, loss: 0.20007, acc:0.80000\n",
      "[Train] Step: 46999, loss: 0.15011, acc:0.85000\n",
      "[Train] Step: 47499, loss: 0.09999, acc:0.90000\n",
      "[Train] Step: 47999, loss: 0.10328, acc:0.90000\n",
      "[Train] Step: 48499, loss: 0.34999, acc:0.65000\n",
      "[Train] Step: 48999, loss: 0.15809, acc:0.85000\n",
      "[Train] Step: 49499, loss: 0.32048, acc:0.65000\n",
      "[Train] Step: 49999, loss: 0.15022, acc:0.85000\n",
      "[Test] Step: 50000, acc: 0.82150\n",
      "[Train] Step: 50499, loss: 0.10619, acc:0.90000\n",
      "[Train] Step: 50999, loss: 0.20084, acc:0.80000\n",
      "[Train] Step: 51499, loss: 0.21883, acc:0.80000\n",
      "[Train] Step: 51999, loss: 0.25000, acc:0.75000\n",
      "[Train] Step: 52499, loss: 0.25414, acc:0.75000\n",
      "[Train] Step: 52999, loss: 0.00170, acc:1.00000\n",
      "[Train] Step: 53499, loss: 0.15248, acc:0.85000\n",
      "[Train] Step: 53999, loss: 0.20000, acc:0.80000\n",
      "[Train] Step: 54499, loss: 0.20000, acc:0.80000\n",
      "[Train] Step: 54999, loss: 0.06838, acc:0.90000\n",
      "[Test] Step: 55000, acc: 0.82300\n",
      "[Train] Step: 55499, loss: 0.00965, acc:1.00000\n",
      "[Train] Step: 55999, loss: 0.19335, acc:0.80000\n",
      "[Train] Step: 56499, loss: 0.05631, acc:0.95000\n",
      "[Train] Step: 56999, loss: 0.09216, acc:0.90000\n",
      "[Train] Step: 57499, loss: 0.10788, acc:0.90000\n",
      "[Train] Step: 57999, loss: 0.05002, acc:0.95000\n",
      "[Train] Step: 58499, loss: 0.20487, acc:0.80000\n",
      "[Train] Step: 58999, loss: 0.31423, acc:0.65000\n",
      "[Train] Step: 59499, loss: 0.15011, acc:0.85000\n",
      "[Train] Step: 59999, loss: 0.10049, acc:0.90000\n",
      "[Test] Step: 60000, acc: 0.82350\n",
      "[Train] Step: 60499, loss: 0.05472, acc:0.95000\n",
      "[Train] Step: 60999, loss: 0.19996, acc:0.80000\n",
      "[Train] Step: 61499, loss: 0.10049, acc:0.90000\n",
      "[Train] Step: 61999, loss: 0.12163, acc:0.85000\n",
      "[Train] Step: 62499, loss: 0.20034, acc:0.80000\n",
      "[Train] Step: 62999, loss: 0.14998, acc:0.85000\n",
      "[Train] Step: 63499, loss: 0.10019, acc:0.90000\n",
      "[Train] Step: 63999, loss: 0.15000, acc:0.85000\n",
      "[Train] Step: 64499, loss: 0.05010, acc:0.95000\n",
      "[Train] Step: 64999, loss: 0.15058, acc:0.85000\n",
      "[Test] Step: 65000, acc: 0.82100\n",
      "[Train] Step: 65499, loss: 0.40019, acc:0.60000\n",
      "[Train] Step: 65999, loss: 0.00004, acc:1.00000\n",
      "[Train] Step: 66499, loss: 0.05002, acc:0.95000\n",
      "[Train] Step: 66999, loss: 0.20234, acc:0.80000\n",
      "[Train] Step: 67499, loss: 0.15000, acc:0.85000\n",
      "[Train] Step: 67999, loss: 0.30100, acc:0.70000\n",
      "[Train] Step: 68499, loss: 0.15007, acc:0.85000\n",
      "[Train] Step: 68999, loss: 0.20255, acc:0.75000\n",
      "[Train] Step: 69499, loss: 0.10381, acc:0.90000\n",
      "[Train] Step: 69999, loss: 0.10112, acc:0.90000\n",
      "[Test] Step: 70000, acc: 0.82300\n",
      "[Train] Step: 70499, loss: 0.04984, acc:0.95000\n",
      "[Train] Step: 70999, loss: 0.10326, acc:0.90000\n",
      "[Train] Step: 71499, loss: 0.15000, acc:0.85000\n",
      "[Train] Step: 71999, loss: 0.05383, acc:0.95000\n",
      "[Train] Step: 72499, loss: 0.05601, acc:0.95000\n",
      "[Train] Step: 72999, loss: 0.06672, acc:0.90000\n",
      "[Train] Step: 73499, loss: 0.15103, acc:0.85000\n",
      "[Train] Step: 73999, loss: 0.10979, acc:0.90000\n",
      "[Train] Step: 74499, loss: 0.09996, acc:0.90000\n",
      "[Train] Step: 74999, loss: 0.25879, acc:0.75000\n",
      "[Test] Step: 75000, acc: 0.82500\n",
      "[Train] Step: 75499, loss: 0.09681, acc:0.90000\n",
      "[Train] Step: 75999, loss: 0.16489, acc:0.85000\n",
      "[Train] Step: 76499, loss: 0.05542, acc:0.95000\n",
      "[Train] Step: 76999, loss: 0.25041, acc:0.75000\n",
      "[Train] Step: 77499, loss: 0.05076, acc:0.95000\n",
      "[Train] Step: 77999, loss: 0.15404, acc:0.85000\n",
      "[Train] Step: 78499, loss: 0.25000, acc:0.75000\n",
      "[Train] Step: 78999, loss: 0.10637, acc:0.90000\n",
      "[Train] Step: 79499, loss: 0.31061, acc:0.70000\n",
      "[Train] Step: 79999, loss: 0.10200, acc:0.90000\n",
      "[Test] Step: 80000, acc: 0.82150\n",
      "[Train] Step: 80499, loss: 0.20043, acc:0.80000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step: 80999, loss: 0.21220, acc:0.80000\n",
      "[Train] Step: 81499, loss: 0.33383, acc:0.65000\n",
      "[Train] Step: 81999, loss: 0.15794, acc:0.85000\n",
      "[Train] Step: 82499, loss: 0.10000, acc:0.90000\n",
      "[Train] Step: 82999, loss: 0.16757, acc:0.80000\n",
      "[Train] Step: 83499, loss: 0.00000, acc:1.00000\n",
      "[Train] Step: 83999, loss: 0.19999, acc:0.80000\n",
      "[Train] Step: 84499, loss: 0.17881, acc:0.75000\n",
      "[Train] Step: 84999, loss: 0.10696, acc:0.90000\n",
      "[Test] Step: 85000, acc: 0.82450\n",
      "[Train] Step: 85499, loss: 0.20004, acc:0.80000\n",
      "[Train] Step: 85999, loss: 0.00000, acc:1.00000\n",
      "[Train] Step: 86499, loss: 0.13843, acc:0.85000\n",
      "[Train] Step: 86999, loss: 0.25119, acc:0.75000\n",
      "[Train] Step: 87499, loss: 0.25254, acc:0.75000\n",
      "[Train] Step: 87999, loss: 0.30445, acc:0.70000\n",
      "[Train] Step: 88499, loss: 0.20038, acc:0.80000\n",
      "[Train] Step: 88999, loss: 0.10001, acc:0.90000\n",
      "[Train] Step: 89499, loss: 0.15043, acc:0.85000\n",
      "[Train] Step: 89999, loss: 0.10000, acc:0.90000\n",
      "[Test] Step: 90000, acc: 0.82500\n",
      "[Train] Step: 90499, loss: 0.10145, acc:0.90000\n",
      "[Train] Step: 90999, loss: 0.15141, acc:0.85000\n",
      "[Train] Step: 91499, loss: 0.12785, acc:0.85000\n",
      "[Train] Step: 91999, loss: 0.14988, acc:0.85000\n",
      "[Train] Step: 92499, loss: 0.10945, acc:0.90000\n",
      "[Train] Step: 92999, loss: 0.05000, acc:0.95000\n",
      "[Train] Step: 93499, loss: 0.05001, acc:0.95000\n",
      "[Train] Step: 93999, loss: 0.10333, acc:0.90000\n",
      "[Train] Step: 94499, loss: 0.20043, acc:0.80000\n",
      "[Train] Step: 94999, loss: 0.20664, acc:0.80000\n",
      "[Test] Step: 95000, acc: 0.82250\n",
      "[Train] Step: 95499, loss: 0.15079, acc:0.85000\n",
      "[Train] Step: 95999, loss: 0.16353, acc:0.80000\n",
      "[Train] Step: 96499, loss: 0.16741, acc:0.80000\n",
      "[Train] Step: 96999, loss: 0.00048, acc:1.00000\n",
      "[Train] Step: 97499, loss: 0.05064, acc:0.95000\n",
      "[Train] Step: 97999, loss: 0.11501, acc:0.90000\n",
      "[Train] Step: 98499, loss: 0.20001, acc:0.80000\n",
      "[Train] Step: 98999, loss: 0.10328, acc:0.90000\n",
      "[Train] Step: 99499, loss: 0.19986, acc:0.80000\n",
      "[Train] Step: 99999, loss: 0.10083, acc:0.90000\n",
      "[Test] Step: 100000, acc: 0.82200\n"
     ]
    }
   ],
   "source": [
    "init = tf.compat.v1.global_variables_initializer()\n",
    "batch_size = 20\n",
    "train_steps = 100000\n",
    "test_steps = 100\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(train_steps):\n",
    "        batch_data, batch_labels = train_data.next_batch(batch_size)\n",
    "        loss_val, acc_val, _ = sess.run([loss, accuracy, train_op], feed_dict={x:batch_data, y:batch_labels})\n",
    "        if (i+1) %500 == 0:\n",
    "            print (\"[Train] Step: %d, loss: %4.5f, acc:%4.5f\" %(i, loss_val, acc_val))\n",
    "        if (i+1) %5000 ==0:\n",
    "            test_data = CifarData(test_filenames, False)\n",
    "            all_test_acc_val = []\n",
    "            for j in range(test_steps):\n",
    "                test_batch_data, test_batch_labels = test_data.next_batch(batch_size)\n",
    "                test_acc_val = sess.run([accuracy],feed_dict = {x:test_batch_data,y:test_batch_labels})\n",
    "                all_test_acc_val.append(test_acc_val)\n",
    "                test_acc=np.mean(all_test_acc_val)\n",
    "            print('[Test] Step: %d, acc: %4.5f' %(i+1, test_acc))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be92614b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
